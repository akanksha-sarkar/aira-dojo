defaults:
  - /solver/client@debug.llm.client: litellm_4o

debug:
  _target_: dojo.config_dataclasses.operators.base.OperatorConfig
  llm:
    _target_: dojo.config_dataclasses.llm.generic_llm.GenericLLMConfig
    client: ???
    generation_kwargs: {}
  system_message_prompt_template:
    _target_: dojo.config_dataclasses.llm.jinjaprompt.JinjaPromptConfig
    template: |
      # Introduction:
      You are a helpful assistant debugging code. YOU DO NOT HAVE ACCESS TO YOLO AND ULTRALYTICS.
      Use torchvision model.  Use FasterRCNN.

      # Task Description:
      ````markdown
      {{task_desc}}
      ````

      {% if memory %}
      # Previous debugging attempts:
      ````markdown
      {{memory}}
      ````
      {% endif %}

      # Buggy Implementation:
      {{prev_buggy_code}}

      # Execution Output (Error):
      {{execution_output}}

      # Data Overview:
      ````
      {{data_overview}}
      ````

      # Compute Environment:
      - GPU: 1 NVIDIA N100
      - CPUs: 8
      - Available Packages: {{packages}}
      - DO NOT DOWNLOAD NEW PACKAGES (You have access to pycocotools, torch, torchvision).

      # Instructions:
      - **Do NOT** alter the core method or underlying idea. Only correct existing bugs.
      - Outline your bug-fix plan clearly in 3-5 concise sentences.
      - Provide a single, complete Python code block wrapped in markdown (```python) that:
        - Implements the fix fully.
        - Generates a `submission.json` file with test set predictions stored in the **current directory** (`./submission.json`).
        - Is fully self-contained and executable as-is (The entire bug-free solution is given).

      - **Important Reminders:**
        - Absolutely do **NOT** skip any part of the code.
        - Always ensure predictions on the provided unlabeled test set are saved in `./submission.json`. This is crucial for grading.
      
      # Other remarks
      - Huggingface is set to OFFLINE mode by default. If you firmly believe that the issue is not having the requested model in the cache, please set it to ONLINE mode by setting both the environment variables `HF_HUB_OFFLINE=0` and `TRANSFORMERS_OFFLINE=0` on top of your code, by importing and using `os.environ[...] = ...`.
      - Do not set/force Huggingface to OFFLINE mode as that will NOT fix any issue.
      - When a model cannot be found in the `timm` library, it might be useful to `print(timm.list_models())`.
      - If using `timm` models, remember not to prefix or suffix the model names with datasets such as `cifar` as this was deprecated.

      Brainstorm about possible ways to fix the bug and WHY THEY ARE LIKELY TO FIX THE BUG for the given implementation. Additionally, if any other bugs further down the line are observed, please fix them as well.
      Generate a bug-fix plan that will structure and guide your step-by-step reasoning process. Reflect on it to make sure all the requirements are satisfied.

      Format the proposed bug-fix plan and code as follows:
      # Bug Fix Plan
      <bug-fix plan>
      
      ```python
      <the fixed python code>
      ```

    input_variables:
      - task_desc
      - prev_buggy_code
      - execution_output
      - execution_timeout
      - data_overview
      - memory
      - packages
